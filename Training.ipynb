{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 600 first epochs were performed on the reduce dataset (360 000 images). Then to the complete dataset (560 000 images).\n",
    "\n",
    "With batch size of 640 and 360 000 images in the database, 100 epochs took about 3h (a bit less)\n",
    "With batch size of 700 and 560 000 images in the database, 100 epochs took about 4h40\n",
    "\n",
    "\n",
    "WITH METRICS: 200 epochs: Wall time: 11h 33min 22s\n",
    "\n",
    "Current script load the 'final' weigths (which is save if everything goes well)\n",
    "\n",
    "Weights are saved every 100 epochs. I should probably keep wieghts each 1000 epochs (depending on how many time it took to treat the whole data set) 139298/139937\n",
    "\n",
    "\n",
    "Look at the correlation matrix to see if there is a bias in the angle correct prediction. If yes, rebuild the dataset by applying angle of 90/180/270 to try to get something mor or less homogenous\n",
    "1 step: realign every centriole in a 0->90 orientation\n",
    "\n",
    "2ns step: perform reorientation. => rotation of 90/180/270 i can also flip the image\n",
    "\n",
    "Load the 500 epochs save if problem\n",
    "\n",
    "\n",
    "\n",
    "TO DO:\n",
    "\n",
    "To check: Note: in train definition i put the model in train mode (model.train() ) I do not change this statut after.\n",
    "\n",
    "Save the log of accuracy and loss\n",
    "\n",
    "Save the train_loader and validation_loader to don't have to rebuild them (especially because that lead to mixing each time train and validation set\n",
    "\n",
    "\n",
    "IMPORTANT: CHANGE PERFORMED ON gestion of classification/Regression problem (modification of n_classes/n_class call in data_agregator and VGG_schmidtea to modify the call of the number of class. MODIFICATION NOT TESTED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Equipe_Azimzadeh\\Desktop\\Planarians\\tools\\ToolBox.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Equipe_Azimzadeh\\Desktop\\Planarians\\tools\\CNN_Tools.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Equipe_Azimzadeh\\Desktop\\Planarians\\tools\\Dataset_Tools.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "from tools.ToolBox import json_loader\n",
    "from tools.ToolBox import csv_saver\n",
    "\n",
    "from tools.CNN_Tools import VGG_Schmidtea\n",
    "from tools.CNN_Tools import train\n",
    "from tools.CNN_Tools import validate\n",
    "\n",
    "from tools.Dataset_Tools import centriole_dataset\n",
    "from tools.Dataset_Tools import dataset_creator\n",
    "from tools.Dataset_Tools import dataset_loader\n",
    "from tools.Dataset_Tools import dataset_aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'regression'\n",
    "problem = 'classification'\n",
    "\n",
    "\n",
    "if problem == 'classification':\n",
    "    n_class = 72\n",
    "    \n",
    "else:\n",
    "    n_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset = True\n",
    "\n",
    "# Creation/Loading of the Dataset\n",
    "if load_dataset == False:   \n",
    "    train_loader, validation_loader = dataset_creator(path_json = './data_json/',\n",
    "                                                     batch_size = 700,\n",
    "                                                     n_class = n_class,\n",
    "                                                     save_dataset = True)  \n",
    "elif problem == 'classification':\n",
    "    train_loader, validation_loader = dataset_loader(path = './data/',\n",
    "                                                     #train_set = 'train_loader_dataset_b700_unNormalized.pth',\n",
    "                                                     train_set = 'train_data_pregression_b700_unNormalized-003.pth',\n",
    "                                                     #val_set = 'validation_loader_dataset_b700_unNormalized.pth')\n",
    "                                                     val_set = 'validation_data_pregression_b700_unNormalized.pth')\n",
    "    \n",
    "else: \n",
    "    train_loader, validation_loader = dataset_loader(path = './data/',\n",
    "                                                 #train_set = 'train_data_pregression_b700_unNormalized.pth',\n",
    "                                                 train_set = 'data_train_regression_normalized.pth',\n",
    "                                                 val_set = 'validation_data_pregression_b700_unNormalized.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.6.0+cpu  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "load_weight = False\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():                                  \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)\n",
    "\n",
    "\n",
    "# Criterion and CNN loading\n",
    "if problem == 'classification':\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = VGG_Schmidtea(n_classes = n_class).to(device)\n",
    "else: \n",
    "    criterion = nn.MSELoss()\n",
    "    model = VGG_Schmidtea(n_classes = 1).to(device)\n",
    "\n",
    "\n",
    "# Weight loading\n",
    "if load_weight == True:\n",
    "    model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_classification.pth'))\n",
    "\n",
    "\n",
    "# Oprimizer loading\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 306 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Planarians\\tools\\CNN_Tools.ipynb\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_vector, accuracy_vector, confusion_matrix, train_loader, device, problem, criterion, optimizer, epoch, n_class, log_interval)\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m    948\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2422\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2216\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2218\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2219\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2220\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 306 is out of bounds."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the number of epochs to train the model\n",
    "epochs = 1\n",
    "performed_epochs = 0\n",
    "\n",
    "\n",
    "# Let's Train!!\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Instantiate variable to log loss and accuracy\n",
    "    acct, losst, accv, lossv,cmt, cmv  = [], [], [], [], [], []\n",
    "    \n",
    "    train(model, losst, acct, cmt, train_loader, device, problem, criterion, optimizer, epoch, n_class)    \n",
    "    validate(model, lossv, accv, cmv, validation_loader, device, problem, criterion, n_class)\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        torch.save(model.state_dict(),('./weight/VGG_schmidtea_weigth_epoch_regression_normalized' + str(epoch+performed_epochs) + '.pth'))\n",
    "    if epoch%10 == 0:\n",
    "        torch.save(model.state_dict(),('./weight/VGG_schmidtea_weigth_epoch_regression_tmp.pth'))\n",
    "        last_tmp_save = epoch + performed_epochs\n",
    "\n",
    "    \n",
    "    \n",
    "    csv_saver(accv , './metrics/accv.csv')\n",
    "    csv_saver(lossv, './metrics/lossv.csv')\n",
    "    csv_saver(acct , './metrics/acct.csv')\n",
    "    csv_saver(losst, './metrics/losst.csv')\n",
    "    csv_saver(cmt  , './metrics/cmt.csv')\n",
    "    csv_saver(cmv  , './metrics/cmv.csv')\n",
    "    \n",
    "    \n",
    "#torch.save(model.state_dict(),('VGG_schmidtea_weigth_epoch_final.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD CONFUSION MATRIX IN REGISTERED METRICS\n",
    "\n",
    "In CNN_TOOLS , add conf_matrix as arguments and add the arguments here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e1d343ec0562>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcol_sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdf_cm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrix = torch.zeros(n_class, n_class)\n",
    "\n",
    "#model.load_state_dict(torch.load('./weight/VGG_schmidtea_weigth_epoch_regression1500.pth'))\n",
    "model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_classification.pth', map_location = device))\n",
    "\n",
    "\n",
    "for batch_idx, batch in enumerate(validation_loader):\n",
    "    # Copy data to GPU if needed\n",
    "    img = batch['image'].float().to(device)\n",
    "    angle = batch['angle'].long().to(device)\n",
    "    angle = angle // 5\n",
    "    \n",
    "    with torch.no_grad():   \n",
    "        output = model(img)  \n",
    "\n",
    "    # get the index of the max log-probability\n",
    "    pred_angle = output.max(1)[1]\n",
    "\n",
    "    for a, p in zip(angle.view(-1), pred_angle.view(-1)):\n",
    "        confusion_matrix[a.long(), p.long()] +=1\n",
    "            \n",
    "# Data in %\n",
    "col_sum = confusion_matrix.numpy().sum(axis=1)\n",
    "col_sum = np.reshape(col_sum, [n_class, -1])\n",
    "\n",
    "confusion_matrix = confusion_matrix / col_sum\n",
    "    \n",
    "df_cm = pd.DataFrame(confusion_matrix.numpy())\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sn.heatmap(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n",
      "torch.Size([700, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(validation_loader):\n",
    "    print(batch['image'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_72 = np.zeros(72)\n",
    "classes = np.linspace(0,71, 72, dtype = np.int16)\n",
    "\n",
    "for i in train_loader:\n",
    "    for j in i['angle']:\n",
    "        class_72[int(j.numpy()//5)] += 1\n",
    "        \n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(x = classes, weights = class_72, discrete =  True)\n",
    "\n",
    "class_72 = np.zeros(72)\n",
    "classes = np.linspace(0,71, 72, dtype = np.int16)\n",
    "\n",
    "for i in validation_loader:\n",
    "    for j in i['angle']:\n",
    "        class_72[int(j.numpy()//5)] += 1\n",
    "        \n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(x = classes, weights = class_72, discrete =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 0->5     18 = 90->95     36 = 180->185     54 = 270->275\n",
      "1 = 5->10     19 = 95->100     37 = 185->190     55 = 275->280\n",
      "2 = 10->15     20 = 100->105     38 = 190->195     56 = 280->285\n",
      "3 = 15->20     21 = 105->110     39 = 195->200     57 = 285->290\n",
      "4 = 20->25     22 = 110->115     40 = 200->205     58 = 290->295\n",
      "5 = 25->30     23 = 115->120     41 = 205->210     59 = 295->300\n",
      "6 = 30->35     24 = 120->125     42 = 210->215     60 = 300->305\n",
      "7 = 35->40     25 = 125->130     43 = 215->220     61 = 305->310\n",
      "8 = 40->45     26 = 130->135     44 = 220->225     62 = 310->315\n",
      "9 = 45->50     27 = 135->140     45 = 225->230     63 = 315->320\n",
      "10 = 50->55     28 = 140->145     46 = 230->235     64 = 320->325\n",
      "11 = 55->60     29 = 145->150     47 = 235->240     65 = 325->330\n",
      "12 = 60->65     30 = 150->155     48 = 240->245     66 = 330->335\n",
      "13 = 65->70     31 = 155->160     49 = 245->250     67 = 335->340\n",
      "14 = 70->75     32 = 160->165     50 = 250->255     68 = 340->345\n",
      "15 = 75->80     33 = 165->170     51 = 255->260     69 = 345->350\n",
      "16 = 80->85     34 = 170->175     52 = 260->265     70 = 350->355\n",
      "17 = 85->90     35 = 175->180     53 = 265->270     71 = 355->360\n"
     ]
    }
   ],
   "source": [
    "classes = np.linspace(0,71, 72, dtype= np.int16)\n",
    "first_degre = np.linspace(0, 355, 72, dtype = np.int16)\n",
    "second_degre = np.linspace(5,360,72, dtype = np.int16)\n",
    "\n",
    "#for i in range(len(classes)):\n",
    "# print(\"{} = {}->{}\".format(classes[i], first_degre[i], second_degre[i]))\n",
    "\n",
    "dist = int(len(classes)/4)\n",
    "for i in range(dist):\n",
    "    print(\"{} = {}->{}     {} = {}->{}     {} = {}->{}     {} = {}->{}\".format(classes[i], first_degre[i], second_degre[i],\n",
    "                                                                              classes[i+dist], first_degre[i+dist], second_degre[i+dist],\n",
    "                                                                              classes[i+2*dist], first_degre[i+2*dist], second_degre[i+2*dist],\n",
    "                                                                              classes[i+3*dist], first_degre[i+3*dist], second_degre[i+3*dist]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f03af0aa9d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset_train = centriole_dataset(img_db = x_train, angle_db = y_train)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(dataset_train)):\n",
    "    sample = dataset_train[i+10]\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('angle {}°'.format(int(sample['angle'])))\n",
    "    ax.axis('off')\n",
    "    show_centriole(np.array(sample['image'], dtype = 'uint8'))\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = centriole_dataset(img_db = x_test, angle_db = y_test)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(dataset_test)):\n",
    "    sample = dataset_test[i+10]\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('angle {}°'.format(int(sample['angle'])))\n",
    "    ax.axis('off')\n",
    "    show_centriole(np.array(sample['image'], dtype = 'uint8'))\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
