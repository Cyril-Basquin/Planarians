{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import xlrd  \n",
    "\n",
    "from time import time, asctime\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "from tools.Centriole_Characteristic import *\n",
    "from tools.Extract_Experiment_Characteristic import *\n",
    "from tools.CNN_Tools import *\n",
    "from tools.Graphical_Tools import *\n",
    "from tools.Centriole_Detection import *\n",
    "\n",
    "#from tools.Worm_Segmentation import extract_worm_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 27 13:29:30 2020: Start orientation centriole prediction of ./to_analyse/160330_WT_4.tif\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-40829dc8ad45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Predict the centriole, return a list of format ((X, Y), Angle)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcentrioleList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mangle_prediction_from_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{asctime()}: Centrioles angle predicted and compensated'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Planarians\\tools\\CNN_Tools.ipynb\u001b[0m in \u001b[0;36mangle_prediction_from_img\u001b[1;34m(path, model, device, problem)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "path = './to_analyse/160330_WT_4.tif'\n",
    "print(f'{asctime()}: Start orientation centriole prediction of {path}')\n",
    "\n",
    "# CUDA is way faster but not always available\n",
    "if torch.cuda.is_available():                                  \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Load the model\n",
    "model = VGG_Schmidtea(n_classes = 72).to(device)\n",
    "model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_classification.pth', map_location = device))\n",
    "model.eval()\n",
    "\n",
    "# Predict the centriole, return a list of format ((X, Y), Angle)\n",
    "centrioleList = angle_prediction_from_img(path, model, device)\n",
    "print(f'{asctime()}: Centrioles angle predicted and compensated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████▉                                                | 15911/43218 [04:45<08:04, 56.40it/s]"
     ]
    }
   ],
   "source": [
    "detectionpath = path[:-4] + '_centriole_detected.tif'\n",
    "\n",
    "#Read the image\n",
    "img = cv2.imread(detectionpath, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "#Extract the coordinate of detected centrioles\n",
    "ypts, xpts = np.where(img == 1)\n",
    "\n",
    "img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "a_list_of_centriole = []\n",
    "x_shape, y_shape = img.shape[1], img.shape[0] \n",
    "\n",
    "xlim, ylim  = x_shape - 16 , y_shape - 16\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(ypts))):\n",
    "    x, y = xpts[i], ypts[i]\n",
    "\n",
    "    if y > 16 and x > 16 and y < ylim and x < xlim:\n",
    "        #centriole_extracted = img.crop((xpts[i], ypts[i], xpts[i] + 32, ypts[i] + 32))\n",
    "        centriole = img[y-16:y+16, x-16:x+16]\n",
    "        centriole = np.asarray(centriole, dtype = \"uint8\")\n",
    "        centriole = centriole.reshape(1 , 1, 32, 32)\n",
    "        # Inside predictor:\n",
    "        centriole = torch.from_numpy(centriole)\n",
    "        centriole = centriole.float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(centriole)\n",
    "\n",
    "        angle = output.max(1)[1]\n",
    "        angle = angle.numpy()\n",
    "\n",
    "        #print(centriole_extracted)\n",
    "        #angle = predictor(model, centriole_extracted, device, problem = 'classification')\n",
    "        a_list_of_centriole.append(((xpts[i], ypts[i]), angle[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43218\n",
      "46688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################\n",
    "# CENTRIOLE REPOSITIONNING ET REORIENTATION\n",
    "###############################################\n",
    "\n",
    "shiftX = db['image_shift']['x']\n",
    "shiftY = db['image_shift']['y']\n",
    "shifted_centriole_list = []\n",
    "\n",
    "for a_centriole in a_list_of_centriole:\n",
    "    xShifted = a_centriole[0][0] + shiftX\n",
    "    yShifted = a_centriole[0][1] + shiftY\n",
    "    if problem == 'classification':\n",
    "        shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]*5+2.5))\n",
    "    else:\n",
    "        shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]))\n",
    "\n",
    "\n",
    "\n",
    "reoriented_centriole = []\n",
    "for a_centriole in shifted_centriole_list:\n",
    "    tmp_list = list(centriole_characterizator(a_centriole, midline_final))\n",
    "    if db['worm_orientation'] == 'gauche' or db['worm_orientation'] == 'left':\n",
    "        tmp_list[-2] = 1 - tmp_list[-2]\n",
    "        tmp_list[-1] = math.degrees(math.atan2(-math.sin(math.radians(tmp_list[-1])), -math.cos(math.radians(tmp_list[-1]))))\n",
    "    tmp_list.insert(1,a_centriole[0][0])\n",
    "    tmp_list.insert(2,a_centriole[0][1])\n",
    "\n",
    "    reoriented_centriole.append(tmp_list)\n",
    "\n",
    "# Save\n",
    "newPath = pathImg_100x[:-4] + '_DATA.csv'\n",
    "with open(newPath, 'w', newline='') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(reoriented_centriole)\n",
    "\n",
    "\n",
    "print(f'{asctime()}: Centriole Dataset reformated')\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#######################################################\n",
    "# Graphical representation of the results\n",
    "# Code above is not mandatory\n",
    "#######################################################\n",
    "\n",
    "# If you want to see some specific centrioles, add them in the list\n",
    "list_of_desired_centriole = [0]\n",
    "\n",
    "# If you want to see the location of a specific coordinate (Write None if you don't want to see them )\n",
    "X_coordinate = None\n",
    "Y_coordinate = None\n",
    "\n",
    "save_path = pathImg_100x[:-4] + '_schema.tif'\n",
    "Worm_And_Centriole(reoriented_centriole, worm, list_of_desired_centriole, (X_coordinate, Y_coordinate), save = True, path = pathImg_100x[:-4])\n",
    "\n",
    "# Print The graph (worms segmented in 5 antero-posterior parts) + moving average + cstd\n",
    "for i in range(5):\n",
    "    print_a_antero_posterior_result(reoriented_centriole, i, n_ante_post_segment = 5, a_lat_size = 0.1, a_lat_step = 0.05, save = True, path = pathImg_100x[:-4])\n",
    "\n",
    "# Overlap the analysed image with the identified and analyzed centriole represented as an arrow indicating the predicted angle\n",
    "# The starting point of the arrow is the origin of the detected centriole\n",
    "# The Ending point indicate the predicted orientation of the centriole\n",
    "\n",
    "save_figure = True\n",
    "\n",
    "# Each color correspond to a class of 5°\n",
    "# So far the color or 'randomly' attributed for each class\n",
    "\n",
    "# Define the length of the arrow\n",
    "arrowLen = 5\n",
    "\n",
    "# Compute as X/Y coordinates the property of the arrow\n",
    "# WARNING: 18/11/2020. FOR AN UNKNOWN REASON, the angle is rotated by 90° -> I need to check why\n",
    "DATA = []\n",
    "\n",
    "for i in a_list_of_centriole:\n",
    "    angle = i[1] + 90\n",
    "    x = i[0][0]\n",
    "    y = i[0][1]\n",
    "    new_coord = [x-arrowLen*math.cos(math.radians(angle)), y-arrowLen*math.sin(math.radians(angle)), x+arrowLen*math.cos(math.radians(angle)), y+arrowLen*math.sin(math.radians(angle)), angle]\n",
    "    DATA.append(new_coord)\n",
    "\n",
    "DATA = np.array(DATA)\n",
    "\n",
    "cmap = plt.cm.jet\n",
    "cNorm  = colors.Normalize(vmin=np.min(DATA[:,4]), vmax=np.max(DATA[:,4]))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm,cmap=cmap)\n",
    "\n",
    "plt.figure(figsize=(100,50))\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "for idx in range(0,len(DATA[:,1])):\n",
    "    colorVal = scalarMap.to_rgba(DATA[idx,4])\n",
    "    plt.arrow(DATA[idx,0],  #x1\n",
    "              DATA[idx,1],  # y1\n",
    "              DATA[idx,2]-DATA[idx,0], # x2 - x1\n",
    "              DATA[idx,3]-DATA[idx,1], # y2 - y1\n",
    "              color=colorVal)\n",
    "if save_figure: \n",
    "    savePath = pathImg_100x[:-4] + '_Detected_Angle.tif'\n",
    "    plt.savefig(savePath)\n",
    "\n",
    "with open('./file_treated.csv', 'a', newline='') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(tif_list[i])\"\"\"\n",
    "print(f\"{asctime()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
