{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective\n",
    "This is the main notebook of the pipeline that will allow detection and prediction of the rootlet from planarian multiciliated cells\n",
    "\n",
    "Note 13 April 2021: Data Vizualization is not implemented but I think that data are saved as a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/Centriole_Characteristic.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/ToolBox.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/Midline_Edge_Reformater.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/Extract_Experiment_Characteristic.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/CNN_Tools.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/Graphical_Tools.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/Analysis_Tools.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/Centriole_Detection.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Allow importation of the others notebook\n",
    "import import_ipynb\n",
    "\n",
    "# pyTorch: module for the neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# load excel files \n",
    "# note 13 April 2021: the module might be deprecated\n",
    "import xlrd  \n",
    "\n",
    "# time tools\n",
    "from time import time, asctime\n",
    "\n",
    "# module that list all files in a input directory\n",
    "from glob import glob\n",
    " \n",
    "# module that open/save data as csv\n",
    "import csv\n",
    "\n",
    "#import asyncio   # note 13/04/2021, this module was already anotated: might be useless\n",
    "\n",
    "# Data Vizualisation module\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "# helper function \n",
    "# note 13/04/2021 instead of * each function should be load independently\n",
    "from tools.Centriole_Characteristic import *\n",
    "from tools.Extract_Experiment_Characteristic import *\n",
    "from tools.CNN_Tools import *\n",
    "from tools.Graphical_Tools import *\n",
    "from tools.Centriole_Detection import *\n",
    "\n",
    "#from tools.Worm_Segmentation import extract_worm_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 63/100x anti-rootletin image(s) and excel file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell load the preprocess 100x images and the corresponding excel file \n",
    "# Immunofluorescence images acquired at objective 63x or 100x \n",
    "# Excel file with midline and edge coordinate, X- and Y- shift\n",
    "\n",
    "# 2 options are available: \n",
    "optionChosen = 2\n",
    "\n",
    "# OPTION 1:\n",
    "# analyzis of all data in a folder\n",
    "if optionChosen == 1:\n",
    "    tif_list = glob('./to_analyse/*.tif')\n",
    "    xls_list = glob('./to_analyse/*.xlsm')\n",
    "\n",
    "# OPTION 2:\n",
    "# analyse only a specific file, put the path, and uncomment the two lines below:\n",
    "elif optionChosen == 2:\n",
    "    tif_list = ['./full_worm_2/160607_WT_Rootletin_6.xlsm']\n",
    "    xls_list  = ['./full_worm_2/160607_WT_Rootletin_6.tif']\n",
    "    \n",
    "    tif_list = ['./Analyzed/160330_WT_3.xlsm']\n",
    "    xls_list  = ['./Analyzed/160330_WT_3.tif']\n",
    "    \n",
    "else:\n",
    "    print('Option provided was not understood')\n",
    "    \n",
    "    \n",
    "\n",
    "# WARNING: \n",
    "# I'm not sure to put any Quality Check in the script, make sure that the name of both file\n",
    "# .xlsm and .tif share the same name at the exception of the extension\n",
    "\n",
    "# Note: \n",
    "# It's better to put the full path of the file, the './my_directory' is the linux equivalent of 'c:/my_directory'\n",
    "# If Option 2: keep the bracket and the apostrophe ['./whateverYouNeed/xxx.xslm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Cyril the 13/04/2021\n",
    " \n",
    "I annotated the code but i didn't check if it work.\n",
    " \n",
    "From what i looked so far, their is currently no possibility to load some already pre process data (detect centriole one day then predict their angle an other day). This might be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 14 22:35:49 2021\n",
      "Exl file loaded: ./Analyzed/160330_WT_3.tif\n",
      "Tif file loaded: ./Analyzed/160330_WT_3.xlsm\n"
     ]
    },
    {
     "ename": "XLRDError",
     "evalue": "Unsupported format, or corrupt file: Expected BOF record; found b'MM\\x00*\\x00\\x00\\x00\\x08'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5177eae1027b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# 13/04/2021: it looks like the get_xls_values() function open the excel file and load the coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# for midline and edge in this excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xls_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathExcel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx_mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'worm_midline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Planarians/tools/Extract_Experiment_Characteristic.ipynb\u001b[0m in \u001b[0;36mget_xls_values\u001b[0;34m(xls_file_name)\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/planarians/lib/python3.8/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     bk = book.open_workbook_xls(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/planarians/lib/python3.8/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mbiff_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/planarians/lib/python3.8/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mgetbof\u001b[0;34m(self, rqd_stream)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; met end of file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; found %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/planarians/lib/python3.8/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mbof_error\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'MM\\x00*\\x00\\x00\\x00\\x08'"
     ]
    }
   ],
   "source": [
    "# Do you want to save as image the intermediate result (DOG, find_maxima, DOG+find_maxima)\n",
    "# It's memory consuming but since this algorithm is very slow it's better to save the result\n",
    "# especially for publication purpose\n",
    "SAVE_INTERMEDIATE_IMG = True\n",
    "\n",
    "# Do you want to load the 'skeleton' of the worm (midline & edge)\n",
    "LOAD_MIDLINE_AND_EDGE_FROM_EXCEL = True # This should not be ther\n",
    "\n",
    "\n",
    "# Loop that will analyze one by one all the file define above.\n",
    "for pathExcel, pathImg_100x in zip(xls_list, tif_list):\n",
    "    \n",
    "    # print the time when the file start to be compute and the name of both file\n",
    "    print(f\"{asctime()}\")\n",
    "    print(f\"Exl file loaded: {pathExcel}\")\n",
    "    print(f\"Tif file loaded: {pathImg_100x}\") \n",
    "\n",
    "    \n",
    "# 14/04/2021: The 3 lines below seems to be for future development: automatic edge and midline detection\n",
    "    # Are you just testing the angle compensation?\n",
    "    Test_Angle_Compensation = False\n",
    "    path_img_10x   = './full_worm/C1-180417_Dvl1&2_Odf2-injection_root_17dpa_10x_Full_1.tif'\n",
    "\n",
    "    \n",
    "    # Define the method use to predict angle\n",
    "    problem = 'classification'\n",
    "\n",
    "    \n",
    "####################################\n",
    "# MIDLINE AND WORM EDGE    \n",
    "####################################\n",
    "\n",
    "# 13/04/2021: In the future 2 options might be available: \n",
    "# Either the midline and edge will be draw manually with ImageJ\n",
    "# Or an automatic algorithm will do the job\n",
    "# Currently the automatic version is not available\n",
    "\n",
    "    # Load Midline and Edge coordinates from a 'classical' excel file\n",
    "    if LOAD_MIDLINE_AND_EDGE_FROM_EXCEL:\n",
    "\n",
    "# 13/04/2021: To Raphael: perfect example of why it's better to load function individually and not with a *\n",
    "# it have been easier for me to find it and know what function is doing exactly\n",
    "\n",
    "# 13/04/2021: it looks like the get_xls_values() function open the excel file and load the coordinates \n",
    "# for midline and edge in this excel file\n",
    "        db = get_xls_values(pathExcel)\n",
    "\n",
    "        x_mid = db['worm_midline']['x']\n",
    "        y_mid = db['worm_midline']['y']\n",
    "        x_edg = db['worm_edge']['x']\n",
    "        y_edg = db['worm_edge']['y']\n",
    "\n",
    "        # Invert the y axis for edge and midline\n",
    "# 13/04/2021: If i remember well, that's require because imageJ have an invertex y axis (the (0,0) coordinate\n",
    "# is in top left corner, and we want it bottom left corner)\n",
    "        newY_mid, newY_edg = [], []\n",
    "        for y in y_mid:\n",
    "            newY_mid.append(-y)\n",
    "\n",
    "        for y in y_edg:\n",
    "            newY_edg.append(-y)\n",
    "\n",
    "        # 'skeleton' of the worm\n",
    "        worm = [x_mid, newY_mid, x_edg, newY_edg ]\n",
    "\n",
    "\n",
    "    # Automatic characterization of the midline and the edge\n",
    "    ## So far (17 November 2020) do not work at all. \n",
    "    ## Ideas: size of the image, contrast (rm background per example)\n",
    "    else:\n",
    "        midline, edge = extract_worm_edge(path_img_10x, quantile = 0.01)\n",
    "        worm = [midline[0], midline[1], edge[0], edge[1]]\n",
    "\n",
    "    \n",
    "    # Reformat midline and Edge in a given number of segment and subsegment\n",
    "    midline_final = aggregate_segment_char(x_mid, newY_mid, \n",
    "                                           x_edg, newY_edg, \n",
    "                                           n_midline_seg = 50, \n",
    "                                           n_sub_segment = 25, \n",
    "                                           n_edge_seg = 200)\n",
    "\n",
    "\n",
    "    print(f'{asctime()}: Edge and Midline reformated')\n",
    "\n",
    "# 13/04/2021: improvment possibility of the previous function: perform an interpolation of the midline\n",
    "# instead of using segment\n",
    "# might be possible to do it as well for the edge, but perhaps harder because edge is circular\n",
    "\n",
    "\n",
    "#####################################\n",
    "# CENTRIOLES IDENTIFICATION\n",
    "#####################################\n",
    "\n",
    "    # load the 100x image using OpenCV\n",
    "    img = cv2.imread(pathImg_100x, cv2.IMREAD_UNCHANGED)\n",
    "    print(f'{asctime()}: Image Loaded')\n",
    "\n",
    "    # Compute differential of Gaussian then Otsu thresholding to try to get a mask of the centriole\n",
    "    # return a binary image\n",
    "    dog_img = dog_and_otsu(img)\n",
    "    \n",
    "    if SAVE_INTERMEDIATE_IMG:\n",
    "        img_to_save = Image.fromarray(dog_img)\n",
    "        newPath = pathImg_100x[:-4] + '_dog_otsu.tif'\n",
    "        img_to_save.save(newPath)\n",
    "        \n",
    "    print(f'{asctime()}: Dog & Otsu computed ')\n",
    "\n",
    "    \n",
    "    # detect centriole using find_maxima algorithm \n",
    "    # note: find_maxima() is the implementation of the find_maxima module in imageJ\n",
    "    # return a binary image\n",
    "    find_maxima_img = find_maxima(img)\n",
    "    \n",
    "    if SAVE_INTERMEDIATE_IMG:\n",
    "        img_to_save = Image.fromarray(find_maxima_img)\n",
    "        newPath = pathImg_100x[:-4] + '_find_maxima.tif'\n",
    "        img_to_save.save(newPath)\n",
    "        \n",
    "    print(f'{asctime()}: Find Maxima Computed')\n",
    "\n",
    "    \n",
    "    # combine the 2 previous approaches to get the final \n",
    "    # return a binary image\n",
    "    combine_img = dog_img*find_maxima_img\n",
    "    \n",
    "    if SAVE_INTERMEDIATE_IMG:\n",
    "        img_to_save = Image.fromarray(combine_img)\n",
    "        newPath = pathImg_100x[:-4] + '_centriole_detected.tif'\n",
    "        img_to_save.save(newPath)\n",
    "    print(f'{asctime()}: Centriole detected')\n",
    "\n",
    "    \n",
    "# 13/04/2021: I'm almost sure that all the code above this comment work fine.\n",
    "# Due to some comment in the code, it looks like the code below will not work   # THIS COMMENT NEED TO BE UPDATED \n",
    "\n",
    "###########################################\n",
    "# ANGLE PREDICITON OF THE CENTRIOLE\n",
    "###########################################\n",
    "\n",
    "# The prediction is perfomed thanks to a neural network implemented in Python using the pyTorch package\n",
    "\n",
    "    # Define where the prediction will be perform (on cpu or on gpu (graphic card))\n",
    "    # using the gpu require an Nvidia graphic card with cuda installed\n",
    "#13/04/2021: to train a model it's mandatory to use CUDA, to predict the orientation of 'only' 100k\n",
    "# i don't know how much time it will take to use a cpu. using google Colab might be mandatory\n",
    "    if torch.cuda.is_available():                                  \n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    # Loading the Neural Network (VGG_Schmidtea) and the Weight of the network ()\n",
    "#13/04/2021: only classification is working, the path below do not exist, the appropriate weigth might be:\n",
    "# './weight/VGG_schmidtea_weight_classification_noReLu_80percent_classification_n72.pth'\n",
    "    if problem == 'classification':\n",
    "        model = VGG_Schmidtea(n_classes = 72).to(device)\n",
    "        #model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_classification.pth', map_location = device))\n",
    "        model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_classification_noReLu_80percent_classification_n72.pth', map_location = device))\n",
    "\n",
    "    else:\n",
    "        model = VGG_Schmidtea(n_classes = 1).to(device)\n",
    "        model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_regression.pth', map_location = device))\n",
    "\n",
    "    # Put the model in evaluation/prediction mode\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    # Get centriole coordinates from the combine image\n",
    "    ypts, xpts = np.where(combine_img == 1)\n",
    "    \n",
    "    # instantiate a list to store centriole coordinates and predicted angle\n",
    "    a_list_of_centriole = []\n",
    "    \n",
    "    # Note \n",
    "    for x, y in zip(xpts, ypts):\n",
    "\n",
    "        # Ignore centriole located nearby the image edge\n",
    "        if y > 16 and x > 16 and y < (img.shape[0] - 16) and x < (img.shape[1] - 16):\n",
    "            # extract a centriole from the image\n",
    "            centriole = img[y-16:y+16, x-16:x+16]\n",
    "            \n",
    "            # transform it in np array in the appropriate type\n",
    "            centriole = np.asarray(centriole, dtype = \"uint8\")\n",
    "            \n",
    "            # reshape to fit the neural network shape\n",
    "            centriole = centriole.reshape(1 , 1, 32, 32)\n",
    "            \n",
    "            # transform in torch format\n",
    "            centriole = torch.from_numpy(centriole).float()\n",
    "            \n",
    "            # send to the appropriate device\n",
    "            centriole = centriole.to(device)\n",
    "\n",
    "            # predict the angle\n",
    "            with torch.no_grad():\n",
    "                output = model(centriole)\n",
    "\n",
    "            # Get the better prediction as np array\n",
    "            angle = output.max(1)[1].numpy() # might be classification specific\n",
    "\n",
    "            #print(centriole_extracted)\n",
    "# 14/04/2021: I didnt' uncomment nor remove predictor() because i don't know what it is suppose to do \n",
    "# or if it's an laternative\n",
    "            #angle = predictor(model, centriole_extracted, device, problem = 'classification')\n",
    "            a_list_of_centriole.append(((x, y), angle[0]))\n",
    "        \n",
    "# 14/04.2021: WARNING code added to save the list as csv: not tested, due to the structure of the variable\n",
    "# a_list_of_centriole, i'm almost sure that it will not work: the list contain tuples of tuple\n",
    "# NEED TO BE UPDATED: centriole could be append to the list with: a_list_of_centriole.append([x, y, angle[0]])\n",
    "# but this require modification later on in the code\n",
    "    try:\n",
    "        # Save the predicted centriole localization and angle in a csv \n",
    "        with open('pathImg_100x[:-4]_centrioleCoordinates_and_anglePrediction.csv', 'w') as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerow([x_coordinate, y_coordinate, predicted_angle])\n",
    "            write.writerows(a_list_of_centriole)\n",
    "    except: \n",
    "        print(f\"list of centriole coordinates and predicted angle not save in csv\")\n",
    "        \n",
    "    \n",
    "# 14/04/2021: I didn't remove the 'compensated' from the print but except if it's in predictor()\n",
    "# angle orientation has not been compensated for the moment\n",
    "    # print a message to say that all centriole of the worm have been predicted\n",
    "    print(f'{asctime()}: Centrioles angle predicted and compensated')\n",
    "\n",
    "\n",
    "###############################################\n",
    "# CENTRIOLE REPOSITIONNING ET REORIENTATION\n",
    "###############################################\n",
    "\n",
    "    # Load the shift between the 100x image where the centriole have been detected\n",
    "    # and the 10x image where edge and midline have been draw\n",
    "    shiftX = db['image_shift']['x']\n",
    "    shiftY = db['image_shift']['y']\n",
    "    \n",
    "    # instantiate a list to save shifted centriole coordinate and predicted angle\n",
    "    shifted_centriole_list = []\n",
    "\n",
    "# 14/04/2021: the code below is not optimize at all. Vectorization using np array is better\n",
    "    # Shift all centriole \n",
    "    # as for midline and edge, the obtained Y value have to be inverted due to ImageJ format\n",
    "    for a_centriole in a_list_of_centriole:\n",
    "        xShifted = a_centriole[0][0] + shiftX\n",
    "        yShifted = a_centriole[0][1] + shiftY\n",
    "        \n",
    "        # For classification problem transform the class in angle\n",
    "        if problem == 'classification':\n",
    "            shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]*5+2.5))\n",
    "        else:\n",
    "            shifted_centriole_list.append(((xShifted, -yShifted),a_centriole[1]))\n",
    "\n",
    "            \n",
    "    # instantiate a list to save centriole coordinates and compensate centrioles angle\n",
    "    reoriented_centriole = []\n",
    "    \n",
    "# 14/04/2021: the code below is not optimize at all. Vectorization using np array is better\n",
    "# 14/04/2021: I dind't look at centriole_characterizator(), but the code below reorient the predicted angle\n",
    "# thanks to midline orientation and transform centriole absolute coordinate in relative coordinate\n",
    "    for a_centriole in shifted_centriole_list:\n",
    "        tmp_list = list(centriole_characterizator(a_centriole, midline_final))\n",
    "        if db['worm_orientation'] == 'gauche' or db['worm_orientation'] == 'left':\n",
    "            tmp_list[-2] = 1 - tmp_list[-2]\n",
    "            tmp_list[-1] = math.degrees(math.atan2(-math.sin(math.radians(tmp_list[-1])), -math.cos(math.radians(tmp_list[-1]))))\n",
    "        tmp_list.insert(1,a_centriole[0][0])\n",
    "        tmp_list.insert(2,a_centriole[0][1])\n",
    "\n",
    "        reoriented_centriole.append(tmp_list)\n",
    "\n",
    "# 14/04/2021: It could be usefull to save the results in a excel file for easier \n",
    "# need to check if the csv file can be easily open by excel. \n",
    "    # Save the centriole relative coordinate and predicted angle as csv\n",
    "    newPath = pathImg_100x[:-4] + '_DATA.csv'\n",
    "    with open(newPath, 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(reoriented_centriole)\n",
    "\n",
    "    print(f'{asctime()}: Centriole Dataset reformated')\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# 14/04/2021: End of reviewing for today. Code below seems to be only for data visualization\n",
    "##################################################################################################\n",
    "\"\"\"\n",
    "    #######################################################\n",
    "    # Graphical representation of the results\n",
    "    # Code above is not mandatory\n",
    "    #######################################################\n",
    "    \n",
    "    # If you want to see some specific centrioles, add them in the list\n",
    "    list_of_desired_centriole = [0]\n",
    "\n",
    "    # If you want to see the location of a specific coordinate (Write None if you don't want to see them )\n",
    "    X_coordinate = None\n",
    "    Y_coordinate = None\n",
    "\n",
    "    save_path = pathImg_100x[:-4] + '_schema.tif'\n",
    "    Worm_And_Centriole(reoriented_centriole, worm, list_of_desired_centriole, (X_coordinate, Y_coordinate), save = True, path = pathImg_100x[:-4])\n",
    "    \n",
    "    # Print The graph (worms segmented in 5 antero-posterior parts) + moving average + cstd\n",
    "    for i in range(5):\n",
    "        print_a_antero_posterior_result(reoriented_centriole, i, n_ante_post_segment = 5, a_lat_size = 0.1, a_lat_step = 0.05, save = True, path = pathImg_100x[:-4])\n",
    "        \n",
    "    # Overlap the analysed image with the identified and analyzed centriole represented as an arrow indicating the predicted angle\n",
    "    # The starting point of the arrow is the origin of the detected centriole\n",
    "    # The Ending point indicate the predicted orientation of the centriole\n",
    "\n",
    "    save_figure = True\n",
    "\n",
    "    # Each color correspond to a class of 5째\n",
    "    # So far the color or 'randomly' attributed for each class\n",
    "\n",
    "    # Define the length of the arrow\n",
    "    arrowLen = 5\n",
    "\n",
    "    # Compute as X/Y coordinates the property of the arrow\n",
    "    # WARNING: 18/11/2020. FOR AN UNKNOWN REASON, the angle is rotated by 90째 -> I need to check why\n",
    "    DATA = []\n",
    "\n",
    "    for i in a_list_of_centriole:\n",
    "        angle = i[1] + 90\n",
    "        x = i[0][0]\n",
    "        y = i[0][1]\n",
    "        new_coord = [x-arrowLen*math.cos(math.radians(angle)), y-arrowLen*math.sin(math.radians(angle)), x+arrowLen*math.cos(math.radians(angle)), y+arrowLen*math.sin(math.radians(angle)), angle]\n",
    "        DATA.append(new_coord)\n",
    "\n",
    "    DATA = np.array(DATA)\n",
    "\n",
    "    cmap = plt.cm.jet\n",
    "    cNorm  = colors.Normalize(vmin=np.min(DATA[:,4]), vmax=np.max(DATA[:,4]))\n",
    "    scalarMap = cmx.ScalarMappable(norm=cNorm,cmap=cmap)\n",
    "\n",
    "    plt.figure(figsize=(100,50))\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    for idx in range(0,len(DATA[:,1])):\n",
    "        colorVal = scalarMap.to_rgba(DATA[idx,4])\n",
    "        plt.arrow(DATA[idx,0],  #x1\n",
    "                  DATA[idx,1],  # y1\n",
    "                  DATA[idx,2]-DATA[idx,0], # x2 - x1\n",
    "                  DATA[idx,3]-DATA[idx,1], # y2 - y1\n",
    "                  color=colorVal)\n",
    "    if save_figure: \n",
    "        savePath = pathImg_100x[:-4] + '_Detected_Angle.tif'\n",
    "        plt.savefig(savePath)\n",
    "        \n",
    "    with open('./file_treated.csv', 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(tif_list[i])\n",
    "    print(f\"{asctime()}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a_list_of_centriole' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a51bf294951f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mDATA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma_list_of_centriole\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mangle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a_list_of_centriole' is not defined"
     ]
    }
   ],
   "source": [
    "# Overlap the analysed image with the identified and analyzed centriole represented as an arrow \n",
    "# indicating the predicted angle\n",
    "# The starting point of the arrow is the origin of the detected centriole\n",
    "# The Ending point indicate the predicted orientation of the centriole\n",
    "\n",
    "save_figure = True\n",
    "show_figure = True\n",
    "\n",
    "# Each color correspond to a class of 5째\n",
    "# So far the color or 'randomly' attributed for each class\n",
    "\n",
    "# Define the length of the arrow\n",
    "arrowLen = 5\n",
    "\n",
    "# Compute as X/Y coordinates the property of the arrow\n",
    "# WARNING: 18/11/2020. FOR AN UNKNOWN REASON, the angle is rotated by 90째 -> I need to check why\n",
    "DATA = []\n",
    "\n",
    "for i in a_list_of_centriole:\n",
    "    angle = i[1] + 90\n",
    "    x = i[0][0]\n",
    "    y = i[0][1]\n",
    "    new_coord = [x-arrowLen*math.cos(math.radians(angle)), y-arrowLen*math.sin(math.radians(angle)), x+arrowLen*math.cos(math.radians(angle)), y+arrowLen*math.sin(math.radians(angle)), angle]\n",
    "    DATA.append(new_coord)\n",
    "    \n",
    "DATA = np.array(DATA)\n",
    "\n",
    "cmap = plt.cm.jet\n",
    "cNorm  = colors.Normalize(vmin=np.min(DATA[:,4]), vmax=np.max(DATA[:,4]))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm,cmap=cmap)\n",
    "\n",
    "plt.figure(figsize=(100,50))\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "for idx in range(0,len(DATA[:,1])):\n",
    "    colorVal = scalarMap.to_rgba(DATA[idx,4])\n",
    "    plt.arrow(DATA[idx,0],  #x1\n",
    "              DATA[idx,1],  # y1\n",
    "              DATA[idx,2]-DATA[idx,0], # x2 - x1\n",
    "              DATA[idx,3]-DATA[idx,1], # y2 - y1\n",
    "              color=colorVal)\n",
    "if save_figure: \n",
    "    savePath = pathImg_100x[:-4] + '_Detected_Angle.tif'\n",
    "    plt.savefig(savePath)\n",
    "\n",
    "if show_figure:\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical Representation of the worms and the analyzed centrioles\n",
    "# If you want to see some specific centrioles, add them in the list\n",
    "list_of_desired_centriole = [0]\n",
    "\n",
    "# If you want to see the location of a specific coordinate (Write None if you don't want to see them )\n",
    "X_coordinate = None\n",
    "Y_coordinate = None\n",
    "\n",
    "save_path = pathImg_100x[:-4] + '_schema.tif'\n",
    "Worm_And_Centriole(reoriented_centriole, worm, list_of_desired_centriole, (X_coordinate, Y_coordinate), save_path, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the results \n",
    "for i in range(5):\n",
    "    print_a_antero_posterior_result(reoriented_centriole, i, n_ante_post_segment = 5, a_lat_size = 0.1, a_lat_step = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
