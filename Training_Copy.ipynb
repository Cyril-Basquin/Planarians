{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/ToolBox.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/CNN_Tools_copy.ipynb\n",
      "importing Jupyter notebook from /home/cyril_b/projects/Planarians/tools/Dataset_Tools.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "from tools.ToolBox import json_loader\n",
    "from tools.ToolBox import csv_saver\n",
    "\n",
    "from tools.CNN_Tools_copy import VGG_Schmidtea\n",
    "from tools.CNN_Tools_copy import train\n",
    "from tools.CNN_Tools_copy import validate\n",
    "\n",
    "from tools.Dataset_Tools import centriole_dataset\n",
    "from tools.Dataset_Tools import dataset_creator\n",
    "from tools.Dataset_Tools import dataset_loader\n",
    "from tools.Dataset_Tools import dataset_aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'regression'\n",
    "\n",
    "n_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset = True\n",
    "\n",
    "# Creation/Loading of the Dataset\n",
    "if load_dataset == False:   \n",
    "    train_loader, validation_loader = dataset_creator(path_json = './data_json/',\n",
    "                                                     batch_size = 2,\n",
    "                                                     n_class = n_class,\n",
    "                                                     save_dataset = True)  \n",
    "    \n",
    "else: \n",
    "    train_loader, validation_loader = dataset_loader(path = './data/',\n",
    "                                                 #train_set = 'train_data_pregression_b700_unNormalized.pth',\n",
    "                                                 train_set = 'data_train_regression_normalized.pth',\n",
    "                                                 val_set = 'validation_data_pregression_b700_unNormalized.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.6.0  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "load_weight = False\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():                                  \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)\n",
    "\n",
    "\n",
    "# Criterion and CNN loading\n",
    "criterion = nn.MSELoss()\n",
    "model = VGG_Schmidtea(n_classes = 2).to(device)\n",
    "\n",
    "\n",
    "# Weight loading\n",
    "if load_weight == True:\n",
    "    #model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_noReLu_80percent_classification_n72.pth'))\n",
    "    model.load_state_dict(torch.load('./weight/VGG_schmidtea_weight_tmp.pth'))\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer loading\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_(model,train_loader, device, problem, criterion, optimizer, epoch, n_class, loss_vector, accuracy_vector):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss, correct = 0, 0\n",
    "        \n",
    "    # Loop over each batch from the training set\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        # Send data to the device (GPU) in the appropriate format\n",
    "        img = batch['image'].float().to(device)\n",
    "        angle = batch['angle'].float().to(device)        \n",
    "\n",
    "        # Zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pass data through the network\n",
    "        output = model(img)\n",
    "        \n",
    "        cosangle = torch.cos(torch.deg2rad(angle))\n",
    "        sinangle = torch.sin(torch.deg2rad(angle))\n",
    "        tangle = torch.stack([sinangle, cosangle]).view((len(angle), 2))\n",
    "        \n",
    "        loss = criterion(output, tangle)\n",
    "\n",
    "        train_loss += loss\n",
    "  \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## Calcul of correct predicted angle\n",
    "        real_angle = torch.rad2deg(torch.atan2(tangle[:,1], tangle[:,0]))\n",
    "        pred_angle = torch.rad2deg(torch.atan2(output[:,1], output[:,0]))\n",
    "\n",
    "        angle_5 = real_angle//5\n",
    "        pred_5 = pred_angle//5\n",
    "        correct += pred_5.eq(angle_5).cpu().sum()\n",
    "            \n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    loss_vector.append(train_loss.detach().cpu().numpy())\n",
    "    \n",
    "    accuracy = correct.to(torch.float32)/len(train_loader.dataset)*100\n",
    "    accuracy_vector.append(accuracy.cpu().numpy())\n",
    "    \n",
    "    print(f\" Training: Loss: {train_loss:.3f}, Accuracy: {accuracy:.1f}    |    \", end = '')\n",
    "    \n",
    "    \n",
    "    \n",
    "def validate_(model, validation_loader, device, problem, criterion, n_class, loss_vector, accuracy_vector):\n",
    "    '''\n",
    "    Input of the function:\n",
    "        model: neural network model in Pytorch\n",
    "        loss_vector: empty array with is assigned by the function\n",
    "        accuracy_vector: empty array with is assigned by the function\n",
    "    '''\n",
    "\n",
    "    val_loss, correct = 0, 0\n",
    "        \n",
    "    i = 0\n",
    "    for batch_idx, batch in enumerate(validation_loader):\n",
    "        i +=1\n",
    "        # Copy data to GPU if needed\n",
    "        img = batch['image'].float().to(device)\n",
    "        angle = batch['angle'].float().to(device)        \n",
    "        \n",
    "        # Pass data through the network\n",
    "        with torch.no_grad():\n",
    "                    \n",
    "            # Pass data through the network\n",
    "            output = model(img)\n",
    "\n",
    "            cosangle = torch.cos(torch.deg2rad(angle))\n",
    "            sinangle = torch.sin(torch.deg2rad(angle))\n",
    "            tangle = torch.stack([sinangle, cosangle]).view((len(angle), 2))\n",
    "\n",
    "            loss = criterion(output, tangle)\n",
    "\n",
    "            val_loss += loss\n",
    "    \n",
    "            real_angle = torch.rad2deg(torch.atan2(tangle[:,1], tangle[:,0]))\n",
    "            pred_angle = torch.rad2deg(torch.atan2(output[:,1], output[:,0]))\n",
    "            \n",
    "            angle_5 = real_angle//5\n",
    "            pred_5 = pred_angle//5\n",
    "            correct += pred_5.eq(angle_5).cpu().sum()\n",
    "            \n",
    "            #angle_list.append(real_angle.detach().flatten().numpy())\n",
    "            #pred_list.append(real_angle.detach().flatten().numpy())\n",
    "            \n",
    "    \n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss.detach().cpu().numpy())\n",
    "    \n",
    "    accuracy = correct.to(torch.float32)/len(validation_loader.dataset)*100\n",
    "    accuracy_vector.append(accuracy.detach().cpu().numpy())\n",
    "    \n",
    "    print(f\" Validation: Loss: {val_loss:.3f}, Accuracy: {accuracy:.1f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training: Loss: 0.509, Accuracy: 1.4    |     Validation: Loss: 0.512, Accuracy: 1.4\n",
      "Epoch 1 Training: Loss: 0.507, Accuracy: 1.4    |     Validation: Loss: 0.510, Accuracy: 1.3\n",
      "Epoch 2 Training: Loss: 0.506, Accuracy: 1.4    |     Validation: Loss: 0.509, Accuracy: 1.4\n",
      "Epoch 3 Training: Loss: 0.505, Accuracy: 1.4    |     Validation: Loss: 0.506, Accuracy: 1.5\n",
      "Epoch 4 Training: Loss: 0.504, Accuracy: 1.4    |     Validation: Loss: 0.506, Accuracy: 1.5\n",
      "Epoch 5 Training: Loss: 0.504, Accuracy: 1.4    |     Validation: Loss: 0.506, Accuracy: 1.4\n",
      "Epoch 6 Training: Loss: 0.504, Accuracy: 1.4    |     Validation: Loss: 0.507, Accuracy: 1.4\n",
      "Epoch 7 Training: Loss: 0.503, Accuracy: 1.4    |     Validation: Loss: 0.505, Accuracy: 1.5\n",
      "Epoch 8 Training: Loss: 0.503, Accuracy: 1.4    |     Validation: Loss: 0.504, Accuracy: 1.5\n",
      "Epoch 9 Training: Loss: 0.503, Accuracy: 1.4    |     Validation: Loss: 0.505, Accuracy: 1.4\n",
      "CPU times: user 44min 30s, sys: 7.01 s, total: 44min 37s\n",
      "Wall time: 29min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for epoch in range(10):\n",
    "    losst, lossv = [], []\n",
    "    accut, accuv = [], []\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch}\", end = '')\n",
    "    train_(model, train_loader, device, problem, criterion, optimizer, epoch, n_class, losst, accut)\n",
    "    validate_(model, validation_loader, device, problem, criterion, n_class, lossv, accuv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5078406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(1.3975164, dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(losst[0])\n",
    "lossv\n",
    "accut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, validation_loader = dataset_loader(path = './data/',\n",
    "                                                 #train_set = 'train_data_pregression_b700_unNormalized.pth',\n",
    "                                                 train_set = 'data_train_regression_normalized.pth',\n",
    "                                                 val_set = 'validation_data_pregression_b700_unNormalized.pth')\n",
    "\n",
    "\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    if idx == 1:\n",
    "        #print(batch['image'][1])\n",
    "        toto = {'image': batch['image'][:2], 'angle':batch['angle'][:2]}\n",
    "        tata = {'image': batch['image'][:4], 'angle':batch['angle'][:4]}\n",
    "        \n",
    "training_ = centriole_dataset(img_db = toto['image'], angle_db = toto['angle'], problem = problem)\n",
    "testing_ = centriole_dataset(img_db = tata['image'], angle_db = tata['angle'], problem = problem)\n",
    "\n",
    "train_loader_ = torch.utils.data.DataLoader(training_, batch_size = 2, shuffle = False, drop_last=True)\n",
    "validation_loader_ = torch.utils.data.DataLoader(testing_, batch_size = 2, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00011239 -0.00674243]\n",
      " [ 0.00023574 -0.00758078]]\n",
      "[[-0.05704826  0.70710678]\n",
      " [ 0.99837142  0.70710678]]\n",
      "tensor([-89.0450, -88.2188])\n",
      "tensor([94.6125, 35.3084], dtype=torch.float64)\n",
      "tensor(0.5050, dtype=torch.float64)\n",
      "\n",
      "\n",
      "[[-0.00018176 -0.0063397 ]\n",
      " [-0.00087792 -0.0050795 ]]\n",
      "[[-0.75925313 -0.06237769]\n",
      " [ 0.65079542 -0.99805262]]\n",
      "tensor([-91.6422, -99.8059])\n",
      "tensor([-175.3033,  -56.8930], dtype=torch.float64)\n",
      "tensor(0.4975, dtype=torch.float64)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "def turn2angl(data):\n",
    "    return(torch.rad2deg(torch.atan2(data[:,1], data[:,0])))\n",
    "\n",
    "for idx, batch in enumerate(validation_loader_):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(batch['image'].float().to('cpu'))\n",
    "        angle = batch['angle'].to('cpu')\n",
    "        \n",
    "        cosangle = torch.cos(torch.deg2rad(angle))\n",
    "        sinangle = torch.sin(torch.deg2rad(angle))\n",
    "        tangle = torch.stack([sinangle, cosangle]).view((len(angle), 2))\n",
    "        \n",
    "        loss = criterion(output, tangle)\n",
    "        \n",
    "        print(output.numpy())\n",
    "        print(tangle.numpy())\n",
    "        \n",
    "        print(turn2angl(output))\n",
    "        print(turn2angl(tangle))\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "        print('\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "for epoch in range(1):\n",
    "    losst, lossv = [], []\n",
    "    accut, accuv = [], []\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch}\", end = '')\n",
    "    train_(model, train_loader_, device, problem, criterion, optimizer, epoch, n_class, losst, accut)\n",
    "    validate_(model, validation_loader, device, problem, criterion, n_class, lossv, accuv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schmidtea",
   "language": "python",
   "name": "schmidtea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
